{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2q27gKz1H20"
   },
   "source": [
    "##### Copyright 2023 The MediaPipe Authors. All Rights Reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TUfAcER1oUS6"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_cQX8dWu4Dv"
   },
   "source": [
    "# Face Stylizer\n",
    "\n",
    "This notebook shows you how to use the MediaPipe Tasks Python API to generate stylize faces given a model and input image. This is an experimental feature, so please report any bugs or issues in this sample through the [GitHub sample repo](https://github.com/googlesamples/mediapipe)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6PN9FvIx614"
   },
   "source": [
    "## Imports and Setup\n",
    "Let's start with installing MediaPipe and the related dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gxbHBsF-8Y_l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in /home/juliotorres/miniconda3/lib/python3.11/site-packages (0.10.0)\n",
      "Requirement already satisfied: absl-py in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from mediapipe) (1.4.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from mediapipe) (22.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from mediapipe) (2.0)\n",
      "Requirement already satisfied: matplotlib in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from mediapipe) (3.8.0)\n",
      "Requirement already satisfied: numpy in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from mediapipe) (1.25.2)\n",
      "Requirement already satisfied: opencv-contrib-python in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from mediapipe) (4.8.0.76)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: CFFI>=1.0 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from matplotlib->mediapipe) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from matplotlib->mediapipe) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from matplotlib->mediapipe) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from matplotlib->mediapipe) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from matplotlib->mediapipe) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from matplotlib->mediapipe) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pycparser in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in /home/juliotorres/miniconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a49D7h4TVmru"
   },
   "source": [
    "## Download the face stylizer model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHXsuWDxpOj4"
   },
   "source": [
    "The next thing you will need to do is download the face stylizer model that will be used for this demo. This model is already trained with a pre-determined style that will be used for face stylization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OMjuVQiDYJKF"
   },
   "outputs": [],
   "source": [
    "#@title Start downloading here.\n",
    "!wget -O face_stylizer.task -q https://storage.googleapis.com/mediapipe-models/face_stylizer/blaze_face_stylizer/float32/latest/face_stylizer_color_sketch.task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83PEJNp9yPBU"
   },
   "source": [
    "## Download a test image\n",
    "\n",
    "After downloading the model, you will need to download an image that you can use for testing! It's worth noting that while this is working with a single image, you can download a collection of images to store in the `IMAGE_FILENAMES` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tzXuqyIBlXer"
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "IMAGE_FILENAMES = ['business-person.png']\n",
    "\n",
    "for name in IMAGE_FILENAMES:\n",
    "  url = f'https://storage.googleapis.com/mediapipe-assets/{name}'\n",
    "  urllib.request.urlretrieve(url, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8XRmapjySMN"
   },
   "source": [
    "## Preview the downloaded image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eu_q-Z03r-ed"
   },
   "source": [
    "You can ensure that everything has downloaded correctly by using the following code to display the downloaded image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8rjHk72-lmHX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business-person.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "#from google.colab.patches import cv2_imshow\n",
    "import math\n",
    "\n",
    "def cv2_imshow(img):\n",
    "    return img\n",
    "\n",
    "# Height and width that will be used by the model\n",
    "DESIRED_HEIGHT = 480\n",
    "DESIRED_WIDTH = 480\n",
    "\n",
    "# Performs resizing and showing the image\n",
    "def resize_and_show(image):\n",
    "  h, w = image.shape[:2]\n",
    "  if h < w:\n",
    "    img = cv2.resize(image, (DESIRED_WIDTH, math.floor(h/(w/DESIRED_WIDTH))))\n",
    "  else:\n",
    "    img = cv2.resize(image, (math.floor(w/(h/DESIRED_HEIGHT)), DESIRED_HEIGHT))\n",
    "  cv2_imshow(img)\n",
    "\n",
    "\n",
    "# Preview the image(s)\n",
    "images = {name: cv2.imread(name) for name in IMAGE_FILENAMES}\n",
    "for name, image in images.items():\n",
    "  print(name)\n",
    "  resize_and_show(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iy4r2_ePylIa"
   },
   "source": [
    "## Running inference and visualizing the results\n",
    "To run inference using the face stylizer MediaPipe Task, you will need to initialize the `FaceStylizer` using the model. Once the stylizer has been initialized, you can use the sytlize method to apply the pre-trained model style onto your image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Yl_Oiye4mUuo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-22 11:02:41.600279: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-22 11:02:41.628179: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Image tflite models are assumed to have a single subgraph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m options \u001b[38;5;241m=\u001b[39m vision\u001b[38;5;241m.\u001b[39mFaceStylizerOptions(base_options\u001b[38;5;241m=\u001b[39mbase_options)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Create the face stylizer\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFaceStylizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_from_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m stylizer:\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m   \u001b[38;5;66;03m# Loop through demo image(s)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m image_file_name \u001b[38;5;129;01min\u001b[39;00m IMAGE_FILENAMES:\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Create the MediaPipe image file that will be stylized\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     image \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mcreate_from_file(image_file_name)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/mediapipe/tasks/python/vision/face_stylizer.py:160\u001b[0m, in \u001b[0;36mFaceStylizer.create_from_options\u001b[0;34m(cls, options)\u001b[0m\n\u001b[1;32m    141\u001b[0m   options\u001b[38;5;241m.\u001b[39mresult_callback(\n\u001b[1;32m    142\u001b[0m       stylized_image,\n\u001b[1;32m    143\u001b[0m       image,\n\u001b[1;32m    144\u001b[0m       stylized_image_packet\u001b[38;5;241m.\u001b[39mtimestamp\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m    145\u001b[0m       \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m _MICRO_SECONDS_PER_MILLISECOND,\n\u001b[1;32m    146\u001b[0m   )\n\u001b[1;32m    148\u001b[0m task_info \u001b[38;5;241m=\u001b[39m _TaskInfo(\n\u001b[1;32m    149\u001b[0m     task_graph\u001b[38;5;241m=\u001b[39m_TASK_GRAPH_NAME,\n\u001b[1;32m    150\u001b[0m     input_streams\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    158\u001b[0m     task_options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    159\u001b[0m )\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_graph_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_flow_limiting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mode\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_RunningMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLIVE_STREAM\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpackets_callback\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_callback\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/mediapipe/tasks/python/vision/core/base_vision_task_api.py:70\u001b[0m, in \u001b[0;36mBaseVisionTaskApi.__init__\u001b[0;34m(self, graph_config, running_mode, packet_callback)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m packet_callback:\n\u001b[1;32m     66\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     67\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe vision task is in image or video mode, a user-defined result \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     68\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallback should not be provided.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     69\u001b[0m   )\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_runner \u001b[38;5;241m=\u001b[39m \u001b[43m_TaskRunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpacket_callback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_mode \u001b[38;5;241m=\u001b[39m running_mode\n",
      "\u001b[0;31mValueError\u001b[0m: Image tflite models are assumed to have a single subgraph."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "\n",
    "# Create the options that will be used for FaceStylizer\n",
    "base_options = python.BaseOptions(model_asset_path='face_stylizer.task')\n",
    "options = vision.FaceStylizerOptions(base_options=base_options)\n",
    "\n",
    "# Create the face stylizer\n",
    "with vision.FaceStylizer.create_from_options(options) as stylizer:\n",
    "\n",
    "  # Loop through demo image(s)\n",
    "  for image_file_name in IMAGE_FILENAMES:\n",
    "\n",
    "    # Create the MediaPipe image file that will be stylized\n",
    "    image = mp.Image.create_from_file(image_file_name)\n",
    "    # Retrieve the stylized image\n",
    "    stylized_image = stylizer.stylize(image)\n",
    "\n",
    "    # Show the stylized image\n",
    "    rgb_stylized_image = cv2.cvtColor(stylized_image.numpy_view(), cv2.COLOR_BGR2RGB)\n",
    "    resize_and_show(rgb_stylized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
